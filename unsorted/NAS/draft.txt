Sleep represents a fundamental biological process with profound implications for human health and wellbeing. As a complex physiological state involving coordinated changes across multiple organ systems, sleep provides a unique window into overall health status and disease risk. The elderly population, in particular, experiences significant sleep disturbances that correlate with various health conditions, including cardiovascular diseases, respiratory disorders, and cognitive decline. Polysomnography (PSG), considered the gold standard for sleep assessment, captures multiple physiological signals simultaneously, including electroencephalography (EEG), electrocardiography (ECG), electromyography (EMG), respiratory effort, airflow, and oxygen saturation. These recordings generate rich, multi-dimensional data that reflect the intricate interplay between sleep architecture and systemic health.

Despite the comprehensive nature of PSG data, traditional clinical practice often reduces this information to simplified summary metrics, such as the apnea-hypopnea index (AHI) or sleep efficiency measures. This reductive approach discards substantial temporal and multimodal information that may contain valuable health indicators. Manual annotation of PSG recordings is time-consuming, labor-intensive, and subject to inter-rater variability, creating bottlenecks in clinical workflows and limiting the scalability of sleep-based health assessments. These challenges are particularly pronounced in resource-constrained settings, where access to specialized sleep clinics and trained polysomnography technicians remains limited.

Recent advances in artificial intelligence, particularly in foundation models and self-supervised learning, have opened new avenues for automated analysis of PSG data. Foundation models, which learn general-purpose representations from large-scale unlabeled data, have demonstrated remarkable success across various biomedical domains. The application of these approaches to sleep medicine represents a paradigm shift from traditional feature engineering toward end-to-end learning systems capable of extracting latent physiological patterns directly from raw signals.

Several recent studies have demonstrated the potential of foundation models in sleep analysis. The SleepFounder model introduced a zero-burden approach to sleep monitoring using cardiorespiratory signals derived from heartbeat and respiration data. Trained on a large multi-ethnic dataset comprising thousands of individuals and hundreds of thousands of recording hours, this model employed a ResNet-based feature extractor combined with a RoFormer encoder to process temporal dependencies. The model utilized physiology-inspired pretext tasks, including EEG spectrogram reconstruction and oxygen desaturation prediction, demonstrating that cardiorespiratory signals effectively capture core sleep physiology. Notably, SleepFounder achieved strong performance across multiple downstream tasks, including sleep staging, obstructive sleep apnea (OSA) detection, and demographic profiling, while maintaining robust data efficiency even with limited labeled samples.

The Stanford Sleep Bench project established a comprehensive benchmarking framework for evaluating pre-training methods in sleep foundation models. By systematically comparing self-supervised representation learning (SSRL) approaches—including masked autoencoders, denoising autoencoders, and contrastive learning—across standardized downstream tasks, this work provided crucial insights into the relative strengths of different pre-training strategies. The study found that contrastive learning methods demonstrated superior performance on complex prediction tasks such as disease risk estimation and mortality prediction, while frequency-domain methods proved more effective for sleep staging and apnea diagnosis. These findings underscore the importance of task-appropriate pre-training strategies and standardized evaluation protocols in sleep AI research.

The SleepFM model further extended the scope of sleep-based disease prediction by developing a multimodal foundation model trained on approximately 585,000 hours of sleep recordings from diverse cohorts. Employing a channel-agnostic architecture with leave-one-out contrastive learning, SleepFM demonstrated the ability to predict 130 future diseases with clinically meaningful accuracy, including mortality, heart failure, chronic kidney disease, and dementia. The model's two-phase approach—channel-agnostic multimodal pre-training followed by task-specific fine-tuning—enabled strong generalization across different cohorts and temporal periods. Importantly, the study revealed differential predictive power across sleep stages and signal modalities, with Stage 1/2 and REM sleep generally providing stronger predictive signals, and different modalities showing specialized relevance for specific disease categories.

A complementary foundation model approach focused specifically on risk stratification through unsupervised learning of PSG embeddings. Using a transformer-based architecture trained on over 10,000 PSG studies paired with longitudinal electronic medical records, researchers identified distinct sleep-based risk groups through unsupervised clustering of learned representations. These embedding-derived risk groups demonstrated strong monotonic associations with cardiovascular disease, neurological outcomes, and all-cause mortality over long-term follow-up, outperforming traditional metrics such as AHI in predicting long-term health outcomes. The model's ability to discover latent sleep phenotypes without explicit disease labels highlights the potential of unsupervised learning for identifying novel risk stratification biomarkers.

Beyond general foundation models, numerous studies have investigated the relationship between specific physiological signals recorded during sleep and targeted disease outcomes. Cardiovascular disease prediction has received particular attention given the well-established bidirectional relationship between sleep disorders and cardiovascular health.

The development of the SleepCVD-Net model exemplifies targeted multimodal approaches for cardiovascular disease screening. This architecture employs three parallel deep neural networks to independently analyze single-lead ECG, airflow, and oxygen saturation signals collected during nocturnal PSG recordings. By processing each modality through specialized sub-networks before fusion, the model achieved mean accuracy exceeding 97% for differentiating between controls and patients with stroke, angina, and congestive heart failure. The high performance demonstrated by SleepCVD-Net suggests that nocturnal physiological signatures captured during PSG contain distinctive patterns associated with specific cardiovascular pathologies.

Self-supervised learning approaches have also proven effective for extracting cardiovascular risk markers from PSG data without requiring extensive manual annotations. One study employed a residual-transformer architecture trained via masked signal reconstruction to learn latent representations from raw EEG, ECG, and respiratory signals. By computing disease-specific projection scores—derived from the difference between latent centroids of disease-positive and disease-negative groups—the model generated interpretable scalar measures of alignment with disease-specific physiological patterns. These projection scores, when combined with traditional risk factors, consistently improved prediction of prevalent and incident cardiovascular outcomes beyond the Framingham Risk Score, with strong modality-specific associations emerging: ECG-derived scores predicted cardiac arrhythmias and heart failure, while EEG-derived scores associated with hypertension and cardiovascular mortality.

The integration of sleep-stage information with ECG-based features has yielded additional insights into cardiovascular risk assessment. Research investigating biological age estimation from sleep patterns and ECG signals demonstrated that combining heart rate variability patterns extracted through unsupervised clustering with sleep-stage annotations provided superior cardiovascular risk stratification compared to either modality alone. The resulting biological age estimates showed stronger associations with cardiovascular outcomes and all-cause mortality than chronological age, particularly when distinguishing high-risk from low-risk patients. Kaplan-Meier survival analyses confirmed that integration of sleep and cardiac information captured multidimensional health deterioration not reflected in conventional age-based assessments.

For patients with suspected obstructive sleep apnea, machine learning models incorporating both clinical features and sleep-derived parameters have demonstrated utility for cardiovascular risk prediction. An AdaBoost-based model trained on 5,234 cardiovascular disease-free patients achieved an area under the curve (AUC) of 0.78 for predicting six-year major adverse cardiovascular events and mortality. Feature importance analysis revealed that while age remained the strongest predictor, sleep-derived features such as mean heart rate and oxygen desaturation indices provided complementary predictive value, particularly for women and patients under 60 years of age. The model's interpretability, achieved through extraction of decision rules with specific feature thresholds, facilitated clinical application and risk communication.

The predictive scope of sleep data extends beyond cardiovascular conditions to encompass metabolic, neurological, and systemic disorders. Research utilizing long short-term memory (LSTM) networks to analyze actigraph-derived sleep-wake patterns combined with clinical history data demonstrated feasibility of detecting multiple chronic conditions, including diabetes, chronic kidney disease, and sleep apnea. While performance varied across conditions—with diabetes and apnea detection achieving higher accuracy than hypertension—the study established proof-of-concept for multi-disease screening from sleep behavior patterns. Statistical analysis of misclassified cases revealed that incorporating specific clinical parameters relevant to each disease improved detection accuracy, suggesting the importance of disease-specific feature engineering.

The comprehensive disease prediction capabilities of large-scale foundation models further illustrate the breadth of health information encoded in PSG signals. Using a phenome-wide association study (PheWAS) approach, researchers systematically evaluated predictability of health conditions from sleep data, identifying strong predictive signals across diverse disease categories including neoplasms, circulatory conditions, mental disorders, and respiratory diseases. The analysis revealed that certain physiological modalities demonstrated specialized predictive utility: respiratory signals proved informative for pulmonary and skin conditions, ECG signals for cardiovascular disorders, and brain activity signals for neurological conditions. Importantly, this multimodal complementarity suggests that integrating signals across modalities may be essential for comprehensive health assessment.

Despite the promising performance of foundation models and deep learning approaches in sleep-based health assessment, most existing systems involve large-scale architectures with substantial computational requirements. The SleepFM model, trained on 585,000 hours of recordings, and the foundation model for sleep-based risk stratification, utilizing transformer architectures with millions of parameters, exemplify the trend toward increasingly large models in sleep AI research. While these models achieve state-of-the-art performance on benchmark tasks, their computational demands pose significant barriers to deployment in resource-constrained environments, particularly in low-income regions and remote areas where healthcare infrastructure remains limited.

The tension between model performance and computational efficiency represents a critical challenge for translating sleep AI research into practical clinical applications, especially for elderly populations who may benefit from continuous home-based monitoring. Current literature provides limited investigation of model compression techniques, efficient architecture design, or deployment optimization for sleep analysis systems. The Stanford Sleep Bench study briefly explored parameter space limitations but focused primarily on comparing pre-training methods rather than investigating architectural efficiency. Similarly, while the SleepFounder model mentioned data efficiency in terms of labeled sample requirements, it did not address computational efficiency or deployment constraints.

This gap in the literature is particularly significant given the diverse hardware environments in real-world healthcare settings. Elderly care facilities, home monitoring systems, and community health centers in resource-limited regions often rely on low-end computing devices with constrained memory, processing power, and energy budgets. Deploying large-scale foundation models in these contexts requires either cloud-based inference—which introduces latency, privacy concerns, and dependence on reliable internet connectivity—or substantial hardware investments that may prove prohibitive.

Neural Architecture Search (NAS) techniques offer potential solutions for discovering efficient model architectures tailored to specific computational constraints and task requirements. While NAS methods have achieved remarkable success in computer vision and natural language processing, their application to multimodal physiological signal analysis, particularly in the context of sleep medicine, remains underexplored. Differentiable Architecture Search (DARTS), which formulates architecture search as a continuous optimization problem, provides a computationally efficient approach to discovering optimal network structures without exhaustive enumeration of architectural configurations.

The application of NAS techniques to sleep analysis could address multiple objectives simultaneously: optimizing predictive performance across multiple disease targets, minimizing computational complexity for deployment on resource-constrained devices, and discovering efficient strategies for fusing heterogeneous physiological signals. However, current literature on sleep-based health assessment has not systematically investigated these automated model design approaches, representing a significant opportunity for methodological innovation.


Several critical gaps emerge from the existing literature that motivate the present investigation. First, while numerous studies have demonstrated the feasibility of disease prediction from sleep data, most focus on cardiovascular and respiratory conditions, with limited attention to mental health disorders. Given the substantial prevalence of depression, anxiety, and cognitive decline in elderly populations, and the stigma often associated with mental health diagnosis, developing objective sleep-based screening tools for these conditions addresses an important unmet clinical need.

Second, the predominant focus on large-scale foundation models, while advancing state-of-the-art performance, has created a deployment gap wherein the most sophisticated analytical tools remain inaccessible to resource-constrained healthcare settings. The elderly populations most likely to benefit from continuous health monitoring—including those in rural areas, low-income communities, and developing regions—face the greatest barriers to accessing these technologies. Developing lightweight models specifically designed for efficient deployment could democratize access to advanced sleep-based health assessment.

Third, current research has not systematically investigated the trade-offs between model complexity, computational efficiency, and predictive performance across multiple disease targets simultaneously. While some studies have examined modality-specific contributions to prediction, comprehensive analysis of architectural efficiency in multimodal fusion remains limited. The application of Neural Architecture Search techniques to discover optimal architectures for multi-target health risk assessment under computational constraints represents a novel methodological contribution.

Fourth, although several studies have utilized multiple PSG datasets, systematic approaches to dataset harmonization across cohorts with different recording protocols, equipment, and sampling rates require further investigation. Population-level generalization depends critically on robust preprocessing and harmonization strategies that preserve physiologically relevant information while accounting for technical variability across data sources.

Finally, existing literature provides limited investigation of interpretability and explainability in sleep-based disease prediction models, particularly for deployment in clinical contexts where model transparency facilitates trust and actionable insights. While some studies have extracted feature importance or decision rules, comprehensive approaches to understanding what physiological patterns drive predictions across multiple disease categories remain an open research question.

The present work addresses these gaps by developing a lightweight health risk analysis system specifically designed for elderly populations, with explicit attention to computational efficiency, multi-disease assessment including mental health conditions, dataset harmonization, and deployment feasibility in resource-constrained environments. By employing Differentiable Architecture Search to discover efficient multimodal fusion architectures, this research aims to bridge the gap between state-of-the-art performance and practical deployability, ultimately supporting accessible and continuous health monitoring for vulnerable populations.