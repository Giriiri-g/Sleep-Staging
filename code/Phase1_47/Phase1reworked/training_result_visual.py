# import json
# import matplotlib.pyplot as plt

# # ======================================================
# # 1. LOAD HISTORY
# # ======================================================
# # Option A: load from file
# # with open("results.json", "r") as f:
# #     data = json.load(f)

# # Option B: paste JSON directly
# data = {
#   "config": {
#     "disease": "bpdiag",
#     "input_channels": 7,
#     "input_length": 3000,
#     "hidden_dim": 48,
#     "num_nodes": 10,
#     "loss_type": "bce",
#     "pos_weight": 5.0
#   },
#   "stats": {
#     "total": 723,
#     "train": 523,
#     "val": 92,
#     "test": 108,
#     "num_labels": 1,
#     "disease": "bpdiag"
#   },
#   "best_dag": {
#     "0": {
#       "edges": [
#         0,
#         0
#       ],
#       "ops": [
#         8,
#         2
#       ]
#     },
#     "1": {
#       "edges": [
#         1,
#         2
#       ],
#       "ops": [
#         7,
#         5
#       ]
#     },
#     "2": {
#       "edges": [
#         1,
#         2
#       ],
#       "ops": [
#         7,
#         1
#       ]
#     },
#     "3": {
#       "edges": [
#         1,
#         3
#       ],
#       "ops": [
#         3,
#         8
#       ]
#     },
#     "4": {
#       "edges": [
#         3,
#         1
#       ],
#       "ops": [
#         3,
#         8
#       ]
#     },
#     "5": {
#       "edges": [
#         3,
#         0
#       ],
#       "ops": [
#         0,
#         5
#       ]
#     },
#     "6": {
#       "edges": [
#         7,
#         7
#       ],
#       "ops": [
#         4,
#         2
#       ]
#     },
#     "7": {
#       "edges": [
#         5,
#         2
#       ],
#       "ops": [
#         6,
#         9
#       ]
#     },
#     "8": {
#       "edges": [
#         6,
#         3
#       ],
#       "ops": [
#         8,
#         0
#       ]
#     },
#     "9": {
#       "edges": [
#         10,
#         10
#       ],
#       "ops": [
#         2,
#         7
#       ]
#     }
#   },
#   "best_reward": 0.5518389340092534,
#   "derived_dag": {
#     "0": {
#       "edges": [
#         0,
#         0
#       ],
#       "ops": [
#         9,
#         6
#       ]
#     },
#     "1": {
#       "edges": [
#         2,
#         2
#       ],
#       "ops": [
#         0,
#         7
#       ]
#     },
#     "2": {
#       "edges": [
#         1,
#         0
#       ],
#       "ops": [
#         6,
#         7
#       ]
#     },
#     "3": {
#       "edges": [
#         1,
#         0
#       ],
#       "ops": [
#         0,
#         1
#       ]
#     },
#     "4": {
#       "edges": [
#         0,
#         5
#       ],
#       "ops": [
#         8,
#         9
#       ]
#     },
#     "5": {
#       "edges": [
#         6,
#         2
#       ],
#       "ops": [
#         0,
#         6
#       ]
#     },
#     "6": {
#       "edges": [
#         1,
#         6
#       ],
#       "ops": [
#         0,
#         7
#       ]
#     },
#     "7": {
#       "edges": [
#         2,
#         0
#       ],
#       "ops": [
#         8,
#         6
#       ]
#     },
#     "8": {
#       "edges": [
#         6,
#         4
#       ],
#       "ops": [
#         8,
#         5
#       ]
#     },
#     "9": {
#       "edges": [
#         2,
#         9
#       ],
#       "ops": [
#         8,
#         5
#       ]
#     }
#   },
#   "derived_reward": 0.5754195777782938,
#   "history": {
#     "train_loss": [
#       0.6241609483394983,
#       0.6131081854772268,
#       0.6027819422805835,
#       0.6163335895763253,
#       0.6140549754946487,
#       0.6215833127123754,
#       0.6021535887658221,
#       0.6203464466070979,
#       0.6193708564500389,
#       0.626661074236504,
#       0.6182988244782454,
#       0.6273859997965255,
#       0.6059950304481219,
#       0.6080750061281073,
#       0.5943622546375923,
#       0.6223647235324548,
#       0.6135048264977317,
#       0.604551244644249,
#       0.6189989116206859,
#       0.6088060267316471,
#       0.6044153334959498,
#       0.6193745100273276,
#       0.6056294241041508,
#       0.6059954328357049,
#       0.6078367136934268,
#       0.605141370326468,
#       0.5995013235500024,
#       0.612142279987815,
#       0.6019528119069225,
#       0.6207864880561829,
#       0.599261446194079,
#       0.5743922663184832,
#       0.5995470364888509,
#       0.5857934214034171,
#       0.5759548512644738,
#       0.5862055450865308,
#       0.6045483772859633,
#       0.5959601633953598,
#       0.5831462351031274,
#       0.5945594421722604,
#       0.5802590036542161,
#       0.5907253743342633,
#       0.6037988612486881,
#       0.585269200914311,
#       0.5810394510158203,
#       0.5833985111998312,
#       0.5926614981777263,
#       0.5946026475924366,
#       0.5957984503710045,
#       0.5955120483284476
#     ],
#     "train_acc": [
#       69.4339622941407,
#       70.31446540130759,
#       70.56603772835162,
#       70.69182393685827,
#       70.18867923778558,
#       68.1761006439257,
#       70.44025159481936,
#       70.31446540130759,
#       70.06289310425332,
#       68.42767294097996,
#       70.44025159481936,
#       69.18238992211204,
#       70.06289311175077,
#       69.93710694073131,
#       70.56603776583881,
#       69.55974842017551,
#       70.69182389187363,
#       70.44025160981424,
#       69.93710694073131,
#       69.43396228664326,
#       69.68553458369753,
#       68.67924530551119,
#       69.93710694822875,
#       68.55345910450198,
#       69.68553458369753,
#       69.9371069557262,
#       71.194968568454,
#       68.93081763255522,
#       69.05660376608746,
#       66.66666665167179,
#       69.55974845016527,
#       70.4402516023168,
#       70.31446544629223,
#       71.4465409104929,
#       70.69182388437619,
#       69.4339622941407,
#       68.80503147653064,
#       68.93081764005265,
#       70.94339621142022,
#       69.30817613061869,
#       71.32075474697089,
#       69.81132074721954,
#       66.792452852681,
#       69.18238997459412,
#       69.937106918239,
#       69.05660380357466,
#       69.55974842017551,
#       69.18238995959923,
#       69.93710694822875,
#       68.42767297096972
#     ],
#     "val_loss": [
#       0.6684782427290211,
#       0.6327624450559202,
#       0.609511699365533,
#       0.640220556570136,
#       0.6187307290408922,
#       0.6132280191649562,
#       0.6651224105254464,
#       0.6063906381959501,
#       0.6028029426284458,
#       0.6106467583905095,
#       0.6340649166832799,
#       0.6007772165796031,
#       0.622538862021073,
#       0.6097067866636359,
#       0.6054043873496677,
#       0.603329554848049,
#       0.6004955418731855,
#       0.6248665529748668,
#       0.6179573004660399,
#       0.5884966085786405,
#       0.5887516853602036,
#       0.5957956054936284,
#       0.6041244216587233,
#       0.620558509360189,
#       0.5815241842166238,
#       0.5994498418725055,
#       0.6400204754394033,
#       0.5694667373014533,
#       0.5841634467892025,
#       0.588400300430215,
#       0.5843041655809983,
#       0.5733128721299379,
#       0.5624339463918105,
#       0.5611070329728334,
#       0.6614185144071993,
#       0.6055504459401836,
#       0.5975362010624098,
#       0.6486246365567913,
#       0.5816566231458083,
#       0.5523059523623922,
#       0.5694226182025411,
#       0.5749013631240182,
#       0.6414789440839187,
#       0.5977273596369702,
#       0.6093572131965471,
#       0.5790414019771244,
#       0.5856949972069782,
#       0.5606333989164104,
#       0.6044401098852572,
#       0.5699740751929905
#     ],
#     "val_acc": [
#       0.6956521739130435,
#       0.6956521739130435,
#       0.6956521739130435,
#       0.6956521739130435,
#       0.6956521739130435,
#       0.6956521739130435,
#       0.6521739130434783,
#       0.6956521739130435,
#       0.6956521739130435,
#       0.6956521739130435,
#       0.6956521739130435,
#       0.6956521739130435,
#       0.6956521739130435,
#       0.6956521739130435,
#       0.6956521739130435,
#       0.6956521739130435,
#       0.6956521739130435,
#       0.6956521739130435,
#       0.6956521739130435,
#       0.6956521739130435,
#       0.6956521739130435,
#       0.7065217391304348,
#       0.6956521739130435,
#       0.6956521739130435,
#       0.6956521739130435,
#       0.6956521739130435,
#       0.6956521739130435,
#       0.717391304347826,
#       0.6956521739130435,
#       0.6956521739130435,
#       0.6956521739130435,
#       0.6956521739130435,
#       0.717391304347826,
#       0.717391304347826,
#       0.6956521739130435,
#       0.6956521739130435,
#       0.6956521739130435,
#       0.6956521739130435,
#       0.6956521739130435,
#       0.717391304347826,
#       0.6956521739130435,
#       0.6956521739130435,
#       0.6956521739130435,
#       0.6521739130434783,
#       0.6956521739130435,
#       0.6956521739130435,
#       0.6739130434782609,
#       0.7065217391304348,
#       0.6956521739130435,
#       0.6956521739130435
#     ],
#     "val_f1": [
#       0.0,
#       0.0,
#       0.0,
#       0.0,
#       0.0,
#       0.0,
#       0.3846153846153846,
#       0.0,
#       0.0,
#       0.0,
#       0.0,
#       0.0,
#       0.0,
#       0.0,
#       0.0,
#       0.0,
#       0.0,
#       0.0,
#       0.0,
#       0.0,
#       0.0,
#       0.0689655172413793,
#       0.0,
#       0.0,
#       0.0,
#       0.0,
#       0.0,
#       0.38095238095238093,
#       0.0,
#       0.0,
#       0.0,
#       0.0,
#       0.13333333333333333,
#       0.1875,
#       0.0,
#       0.0,
#       0.0,
#       0.0,
#       0.0,
#       0.1875,
#       0.0,
#       0.0,
#       0.0,
#       0.4838709677419355,
#       0.0,
#       0.0,
#       0.5161290322580646,
#       0.18181818181818182,
#       0.0,
#       0.0
#     ],
#     "controller_loss": [
#       0.6022564636543393,
#       0.5984275164703529,
#       1.5913644134998322,
#       3.506155228614807,
#       1.7622721686959266,
#       1.6401322027047476,
#       1.0230796566853921,
#       2.4982706775267918,
#       2.2237296710411707,
#       3.2551934162775678,
#       1.7144501638909182,
#       3.4512619078159332,
#       2.1212188154459,
#       2.0872923319538432,
#       2.846543034911156,
#       2.7520863165458045,
#       2.223945197711388,
#       1.697224340836207,
#       2.475809735804796,
#       2.9345495214064914,
#       2.8005472236002484,
#       2.999908112237851,
#       3.3214935187560815,
#       2.9428764606515565,
#       4.408696921666463,
#       2.9085276275873184,
#       3.313301369547844,
#       3.171065910657247,
#       3.840203803777695,
#       3.3916195829709372,
#       3.536064686377843,
#       3.671396509806315,
#       3.4123406688372295,
#       3.5205093125502267,
#       3.498860732714335,
#       3.30996907663842,
#       3.686239359776179,
#       3.6476177612940472,
#       3.450116225083669,
#       3.932166314125061,
#       3.2069839000701905,
#       3.464540574947993,
#       3.1131367802619936,
#       3.544185241063436,
#       2.937841538588206,
#       2.4854542655249436,
#       2.608672487735748,
#       2.786015285551548,
#       2.7209930737813313,
#       3.007097129027049
#     ],
#     "controller_reward": [
#       0.46983001319478235,
#       0.4699732337630635,
#       0.48269258468819165,
#       0.507161409146429,
#       0.4866901033756107,
#       0.4858331163300321,
#       0.4786612855027341,
#       0.49756141635000034,
#       0.4949808757585647,
#       0.5088116356677888,
#       0.49067970606674477,
#       0.5130611822535137,
#       0.49770313524527693,
#       0.4980907837950906,
#       0.5083855006812661,
#       0.5081806497506378,
#       0.5027087379914246,
#       0.4968144454361305,
#       0.5072358351067678,
#       0.513951501931647,
#       0.5133591884353642,
#       0.5168951513298737,
#       0.5220098364742373,
#       0.5185045917330355,
#       0.5379941763803366,
#       0.5207961490558665,
#       0.5269350339285274,
#       0.5263973710585987,
#       0.5359713470531295,
#       0.531740987620449,
#       0.5349134317643354,
#       0.5378081667354472,
#       0.5359379498675471,
#       0.5386037716769853,
#       0.5396139795723008,
#       0.5385987458568624,
#       0.544484412554684,
#       0.5454266538218158,
#       0.5443244384410139,
#       0.5515787748274287,
#       0.5440084168865627,
#       0.5483965520527323,
#       0.5452972060735791,
#       0.5518389340092534,
#       0.5455512775375054,
#       0.5409725852265834,
#       0.5434309424582789,
#       0.546677249131468,
#       0.5468134526279694,
#       0.551424237531247
#     ],
#     "baseline": [
#       0.46236858248078017,
#       0.46259349086731116,
#       0.46318597964695096,
#       0.46448843632579334,
#       0.46514440698627657,
#       0.46575509497660705,
#       0.4661375311143446,
#       0.46706665373163675,
#       0.4678937521945897,
#       0.46910345637138956,
#       0.4697416415285055,
#       0.47102391553708395,
#       0.4718135071358176,
#       0.47258964605265436,
#       0.4736474278335805,
#       0.47467064756096566,
#       0.4754990191388831,
#       0.47613083904979736,
#       0.47705131969217907,
#       0.4781421167002219,
#       0.4791825421355258,
#       0.48029685005460704,
#       0.4815311760307156,
#       0.4826243825853513,
#       0.4842621279258976,
#       0.4853426217073635,
#       0.48657334116480433,
#       0.48775084631690824,
#       0.48917765626574267,
#       0.49043783059365126,
#       0.4917514438679387,
#       0.49311360394814174,
#       0.4943801440666555,
#       0.49568787468742975,
#       0.4969874413682712,
#       0.49821819511135285,
#       0.49958656379028576,
#       0.5009418112797416,
#       0.5022247739415381,
#       0.5036850663474428,
#       0.5048758892452525,
#       0.506162120679107,
#       0.5073202674151057,
#       0.5086366812834362,
#       0.5097288607267231,
#       0.510653269310236,
#       0.5116227056959473,
#       0.5126589493139972,
#       0.5136695334096,
#       0.5147869109047267
#     ],
#     "entropy": [
#       81.04989954630534,
#       81.0495974222819,
#       81.04947611490886,
#       81.04909057617188,
#       81.04856389363607,
#       81.04860254923503,
#       81.04836095174154,
#       81.04699452718098,
#       81.04607391357422,
#       81.04538701375326,
#       81.04470036824544,
#       81.04451192220053,
#       81.04337031046549,
#       81.04275232950846,
#       81.04304428100586,
#       81.04262873331706,
#       81.04003448486328,
#       81.03891830444336,
#       81.03885065714518,
#       81.03823445638021,
#       81.03809382120768,
#       81.03822123209635,
#       81.03928858439127,
#       81.03860651652018,
#       81.03760452270508,
#       81.03650512695313,
#       81.03699162801107,
#       81.03796157836913,
#       81.03817799886068,
#       81.03640213012696,
#       81.03596115112305,
#       81.03646545410156,
#       81.03852183024088,
#       81.03914260864258,
#       81.03835169474284,
#       81.037242380778,
#       81.03651936848958,
#       81.03662796020508,
#       81.03425521850586,
#       81.03312403361002,
#       81.03235346476237,
#       81.0342887878418,
#       81.03401692708333,
#       81.03120829264323,
#       81.03196233113607,
#       81.03031997680664,
#       81.03053970336914,
#       81.02994054158529,
#       81.03000030517578,
#       81.03123931884765
#     ]
#   }
# }


# history = data["history"]

# epochs = list(range(1, len(history["train_loss"]) + 1))

# # ======================================================
# # 2. TRAINING CURVES
# # ======================================================
# plt.figure(figsize=(12, 4))

# plt.subplot(1, 2, 1)
# plt.plot(epochs, history["train_loss"])
# plt.title("Train Loss")
# plt.xlabel("Epoch")
# plt.grid(True)

# plt.subplot(1, 2, 2)
# plt.plot(epochs, history["train_acc"])
# plt.title("Train Accuracy")
# plt.xlabel("Epoch")
# plt.grid(True)

# plt.tight_layout()
# plt.show()

# # ======================================================
# # 3. VALIDATION CURVES
# # ======================================================
# plt.figure(figsize=(12, 4))

# plt.subplot(1, 3, 1)
# plt.plot(epochs, history["val_loss"])
# plt.title("Validation Loss")
# plt.xlabel("Epoch")
# plt.grid(True)

# plt.subplot(1, 3, 2)
# plt.plot(epochs, history["val_acc"])
# plt.title("Validation Accuracy")
# plt.xlabel("Epoch")
# plt.grid(True)

# plt.subplot(1, 3, 3)
# plt.plot(epochs, history["val_f1"])
# plt.title("Validation F1")
# plt.xlabel("Epoch")
# plt.grid(True)

# plt.tight_layout()
# plt.show()

# # ======================================================
# # 4. CONTROLLER (ENAS) CURVES
# # ======================================================
# plt.figure(figsize=(12, 6))

# plt.subplot(2, 2, 1)
# plt.plot(epochs, history["controller_reward"], color="purple")
# plt.title("Controller Reward")
# plt.xlabel("Epoch")
# plt.grid(True)

# plt.subplot(2, 2, 2)
# plt.plot(epochs, history["controller_loss"], color="red")
# plt.title("Controller Loss")
# plt.xlabel("Epoch")
# plt.grid(True)

# plt.subplot(2, 2, 3)
# plt.plot(epochs, history["baseline"], color="green")
# plt.title("Reward Baseline")
# plt.xlabel("Epoch")
# plt.grid(True)

# plt.subplot(2, 2, 4)
# plt.plot(epochs, history["entropy"], color="orange")
# plt.title("Controller Entropy")
# plt.xlabel("Epoch")
# plt.grid(True)

# plt.tight_layout()
# plt.show()

# # ======================================================
# # 5. COMBINED VIEW (KEY METRICS)
# # ======================================================
# plt.figure(figsize=(10, 6))

# plt.plot(epochs, history["val_f1"], label="Val F1")
# plt.plot(epochs, history["val_acc"], label="Val Acc")
# plt.plot(epochs, history["controller_reward"], label="Reward", linestyle="--")

# plt.title("Validation vs Controller Dynamics")
# plt.xlabel("Epoch")
# plt.legend()
# plt.grid(True)

# plt.show()


import json
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd

# =========================
# CONFIG
# =========================
HISTORY_PATH = "bpdiag_post_enas_history.json"
SAVE_DIR = "plots"
SMOOTH_WINDOW = 5  # moving average smoothing

# =========================
# LOAD HISTORY
# =========================
with open(HISTORY_PATH, "r") as f:
    history = json.load(f)

epochs = np.arange(1, len(history["train_loss"]) + 1)

def smooth(x, k=5):
    if k <= 1:
        return x
    return np.convolve(x, np.ones(k)/k, mode="same")

# =========================
# PLOT: LOSS CURVES
# =========================
plt.figure(figsize=(8, 5))
plt.plot(epochs, history["train_loss"], alpha=0.3, label="Train Loss")
plt.plot(epochs, history["val_loss"], alpha=0.3, label="Val Loss")
plt.plot(epochs, smooth(history["train_loss"], SMOOTH_WINDOW), label="Train Loss (smoothed)")
plt.plot(epochs, smooth(history["val_loss"], SMOOTH_WINDOW), label="Val Loss (smoothed)")
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.title("Training vs Validation Loss")
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

# =========================
# PLOT: AUC CURVES
# =========================
plt.figure(figsize=(8, 5))
plt.plot(epochs, history["roc_auc"], label="ROC AUC")
plt.plot(epochs, history["pr_auc"], label="PR AUC")
plt.plot(epochs, smooth(history["roc_auc"], SMOOTH_WINDOW), linestyle="--", label="ROC AUC (smoothed)")
plt.plot(epochs, smooth(history["pr_auc"], SMOOTH_WINDOW), linestyle="--", label="PR AUC (smoothed)")
plt.xlabel("Epoch")
plt.ylabel("AUC")
plt.title("Ranking Performance")
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

# =========================
# PLOT: PR / F1 METRICS
# =========================
plt.figure(figsize=(9, 5))
plt.plot(epochs, history["f1"], label="F1")
plt.plot(epochs, history["precision"], label="Precision")
plt.plot(epochs, history["recall"], label="Recall")
plt.plot(epochs, smooth(history["f1"], SMOOTH_WINDOW), linestyle="--", label="F1 (smoothed)")
plt.xlabel("Epoch")
plt.ylabel("Score")
plt.title("Threshold-Dependent Metrics (Optimized Threshold)")
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

# =========================
# PLOT: THRESHOLD DYNAMICS
# =========================
plt.figure(figsize=(8, 4))
plt.plot(epochs, history["threshold"])
plt.xlabel("Epoch")
plt.ylabel("Optimal Threshold")
plt.title("Optimal Decision Threshold Over Epochs")
plt.grid(True)
plt.tight_layout()
plt.show()

# =========================
# METRIC CORRELATION MATRIX
# =========================
df = pd.DataFrame({
    "train_loss": history["train_loss"],
    "val_loss": history["val_loss"],
    "roc_auc": history["roc_auc"],
    "pr_auc": history["pr_auc"],
    "f1": history["f1"],
    "precision": history["precision"],
    "recall": history["recall"],
    "threshold": history["threshold"],
})

plt.figure(figsize=(10, 8))
sns.heatmap(
    df.corr(),
    annot=True,
    fmt=".2f",
    cmap="coolwarm",
    square=True
)
plt.title("Metric Correlation Matrix")
plt.tight_layout()
plt.show()
